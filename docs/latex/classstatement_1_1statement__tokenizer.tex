\doxysection{statement.\+statement\+\_\+tokenizer Class Reference}
\label{classstatement_1_1statement__tokenizer}\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \textbf{ \+\_\+\+\_\+init\+\_\+\+\_\+} (self)
\item 
list \textbf{ get\+\_\+tokens} (self, \textbf{ text})
\item 
str \textbf{ \+\_\+\+\_\+str\+\_\+\+\_\+} (self)
\item 
str \textbf{ \+\_\+\+\_\+repr\+\_\+\+\_\+} (self)
\item 
def \textbf{ peform\+Sentence\+Split} (self, \textbf{ text})
\item 
def \textbf{ perform\+Word\+Split} (self, \textbf{ text})
\item 
def \textbf{ get\+All\+Tokens} (self, \textbf{ text})
\item 
def \textbf{ retain\+All\+Tokens} (self, \textbf{ text})
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}


Definition at line \textbf{ 6} of file \textbf{ statement.\+py}.



\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\label{classstatement_1_1statement__tokenizer_a539e367f627418c7f0d210d6f1983f2b}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!\_\_init\_\_@{\_\_init\_\_}}
\index{\_\_init\_\_@{\_\_init\_\_}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\_\_init\_\_()}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \textbf{ 7} of file \textbf{ statement.\+py}.



\doxysubsection{Member Function Documentation}
\mbox{\label{classstatement_1_1statement__tokenizer_a85a8d55580c14f82f58e630ba075026d}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!\_\_repr\_\_@{\_\_repr\_\_}}
\index{\_\_repr\_\_@{\_\_repr\_\_}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\_\_repr\_\_()}
{\footnotesize\ttfamily  str statement.\+statement\+\_\+tokenizer.\+\_\+\+\_\+repr\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \textbf{ 25} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1statement__tokenizer_a9449283c6a72dff3aa0ede6aed4f0186}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!\_\_str\_\_@{\_\_str\_\_}}
\index{\_\_str\_\_@{\_\_str\_\_}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{\_\_str\_\_()}
{\footnotesize\ttfamily  str statement.\+statement\+\_\+tokenizer.\+\_\+\+\_\+str\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \textbf{ 20} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1statement__tokenizer_af31fdead83a1bf102c9c769855cc5965}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!get\_tokens@{get\_tokens}}
\index{get\_tokens@{get\_tokens}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{get\_tokens()}
{\footnotesize\ttfamily  list statement.\+statement\+\_\+tokenizer.\+get\+\_\+tokens (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line \textbf{ 15} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1statement__tokenizer_a43a95712f250e8ded2b23ef48988bc86}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!getAllTokens@{getAllTokens}}
\index{getAllTokens@{getAllTokens}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{getAllTokens()}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+get\+All\+Tokens (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line \textbf{ 40} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1statement__tokenizer_a9e8a94c666203e2e3a1e502381afcbec}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!peformSentenceSplit@{peformSentenceSplit}}
\index{peformSentenceSplit@{peformSentenceSplit}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{peformSentenceSplit()}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+peform\+Sentence\+Split (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line \textbf{ 30} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1statement__tokenizer_a10eb35f9e1c1f020d416d494e0ba5f5b}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!performWordSplit@{performWordSplit}}
\index{performWordSplit@{performWordSplit}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{performWordSplit()}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+perform\+Word\+Split (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line \textbf{ 35} of file \textbf{ statement.\+py}.

\mbox{\label{classstatement_1_1statement__tokenizer_afa19774ffa56f61147efb0a4e84f88b1}} 
\index{statement.statement\_tokenizer@{statement.statement\_tokenizer}!retainAllTokens@{retainAllTokens}}
\index{retainAllTokens@{retainAllTokens}!statement.statement\_tokenizer@{statement.statement\_tokenizer}}
\doxysubsubsection{retainAllTokens()}
{\footnotesize\ttfamily def statement.\+statement\+\_\+tokenizer.\+retain\+All\+Tokens (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{text }\end{DoxyParamCaption})}



Definition at line \textbf{ 45} of file \textbf{ statement.\+py}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
\textbf{ statement.\+py}\end{DoxyCompactItemize}
