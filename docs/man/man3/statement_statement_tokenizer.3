.TH "statement.statement_tokenizer" 3 "Tue Nov 29 2022" "Version 1.0" "natural-english-tokenizer" \" -*- nroff -*-
.ad l
.nh
.SH NAME
statement.statement_tokenizer
.SH SYNOPSIS
.br
.PP
.SS "Public Member Functions"

.in +1c
.ti -1c
.RI "def \fB__init__\fP (self)"
.br
.ti -1c
.RI "list \fBget_tokens\fP (self, \fBtext\fP)"
.br
.ti -1c
.RI "str \fB__str__\fP (self)"
.br
.ti -1c
.RI "str \fB__repr__\fP (self)"
.br
.ti -1c
.RI "def \fBpeformSentenceSplit\fP (self, \fBtext\fP)"
.br
.ti -1c
.RI "def \fBperformWordSplit\fP (self, \fBtext\fP)"
.br
.ti -1c
.RI "def \fBgetAllTokens\fP (self, \fBtext\fP)"
.br
.ti -1c
.RI "def \fBretainAllTokens\fP (self, \fBtext\fP)"
.br
.in -1c
.SH "Detailed Description"
.PP 
Definition at line \fB6\fP of file \fBstatement\&.py\fP\&.
.SH "Constructor & Destructor Documentation"
.PP 
.SS "def statement\&.statement_tokenizer\&.__init__ ( self)"

.PP
Definition at line \fB7\fP of file \fBstatement\&.py\fP\&.
.SH "Member Function Documentation"
.PP 
.SS " str statement\&.statement_tokenizer\&.__repr__ ( self)"

.PP
Definition at line \fB25\fP of file \fBstatement\&.py\fP\&.
.SS " str statement\&.statement_tokenizer\&.__str__ ( self)"

.PP
Definition at line \fB20\fP of file \fBstatement\&.py\fP\&.
.SS " list statement\&.statement_tokenizer\&.get_tokens ( self,  text)"

.PP
Definition at line \fB15\fP of file \fBstatement\&.py\fP\&.
.SS "def statement\&.statement_tokenizer\&.getAllTokens ( self,  text)"

.PP
Definition at line \fB40\fP of file \fBstatement\&.py\fP\&.
.SS "def statement\&.statement_tokenizer\&.peformSentenceSplit ( self,  text)"

.PP
Definition at line \fB30\fP of file \fBstatement\&.py\fP\&.
.SS "def statement\&.statement_tokenizer\&.performWordSplit ( self,  text)"

.PP
Definition at line \fB35\fP of file \fBstatement\&.py\fP\&.
.SS "def statement\&.statement_tokenizer\&.retainAllTokens ( self,  text)"

.PP
Definition at line \fB45\fP of file \fBstatement\&.py\fP\&.

.SH "Author"
.PP 
Generated automatically by Doxygen for natural-english-tokenizer from the source code\&.
