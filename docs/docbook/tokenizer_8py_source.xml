<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<section xmlns="http://docbook.org/ns/docbook" version="5.0" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="_tokenizer_8py_source" xml:lang="en-US">
<title>tokenizer.py</title>
<indexterm><primary>scanner/tokenizer.py</primary></indexterm>
Go to the documentation of this file.<programlisting linenumbering="unnumbered"><anchor xml:id="_tokenizer_8py_source_1l00001"/><link linkend="_namespacetokenizer">00001</link> <emphasis role="keyword">import</emphasis>&#32;os
<anchor xml:id="_tokenizer_8py_source_1l00002"/>00002 <emphasis role="keyword">import</emphasis>&#32;re
<anchor xml:id="_tokenizer_8py_source_1l00003"/>00003 
<anchor xml:id="_tokenizer_8py_source_1l00004"/><link linkend="_classtokenizer_1_1_tokenizer">00004</link> <emphasis role="keyword">class&#32;</emphasis><link linkend="_classtokenizer_1_1_tokenizer">Tokenizer</link>:
<anchor xml:id="_tokenizer_8py_source_1l00005"/>00005 &#32;&#32;&#32;&#32;
<anchor xml:id="_tokenizer_8py_source_1l00006"/><link linkend="_classtokenizer_1_1_tokenizer_1a3e765827220ff62dcb1eea8ef15aece6">00006</link> &#32;&#32;&#32;&#32;<emphasis role="keyword">def&#32;</emphasis><link linkend="_classtokenizer_1_1_tokenizer_1a3e765827220ff62dcb1eea8ef15aece6">__init__</link>(self):
<anchor xml:id="_tokenizer_8py_source_1l00007"/>00007 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a3c0d61f258f23116ff555267ae16f7f0">_stmt_pattern</link>=<emphasis role="stringliteral">&apos;[\w*\s]*[\.|\?|,|;]?&#32;?&apos;</emphasis>
<anchor xml:id="_tokenizer_8py_source_1l00008"/>00008 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a0094707f591524fc876a87c584aea101">_token_pattern</link>=<emphasis role="stringliteral">&apos;\w*|\s*|[\.|\?|,|;]&apos;</emphasis>
<anchor xml:id="_tokenizer_8py_source_1l00009"/>00009 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a83247dadeaff93d3086e1b1c40d298d4">_statements</link>=[]
<anchor xml:id="_tokenizer_8py_source_1l00010"/>00010 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a19ba2b3d3f77a08205b45e8a8512dda6">_tokens</link>=[]
<anchor xml:id="_tokenizer_8py_source_1l00011"/>00011 &#32;&#32;&#32;&#32;
<anchor xml:id="_tokenizer_8py_source_1l00012"/><link linkend="_classtokenizer_1_1_tokenizer_1a660a967b3ee256c372f86f0f133af539">00012</link> &#32;&#32;&#32;&#32;<emphasis role="keyword">def&#32;</emphasis><link linkend="_classtokenizer_1_1_tokenizer_1a660a967b3ee256c372f86f0f133af539">get_statements</link>(self,&#32;text)&#32;-&gt;&#32;list:
<anchor xml:id="_tokenizer_8py_source_1l00013"/>00013 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;regex&#32;=&#32;re.compile(self.<link linkend="_classtokenizer_1_1_tokenizer_1a3c0d61f258f23116ff555267ae16f7f0">_stmt_pattern</link>)
<anchor xml:id="_tokenizer_8py_source_1l00014"/>00014 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a83247dadeaff93d3086e1b1c40d298d4">_statements</link>&#32;=&#32;regex.findall(text)
<anchor xml:id="_tokenizer_8py_source_1l00015"/>00015 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">for</emphasis>&#32;s&#32;<emphasis role="keywordflow">in</emphasis>&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a83247dadeaff93d3086e1b1c40d298d4">_statements</link>:
<anchor xml:id="_tokenizer_8py_source_1l00016"/>00016 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">if</emphasis>&#32;(len(s)==0):&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a83247dadeaff93d3086e1b1c40d298d4">_statements</link>.remove(s)&#32;
<anchor xml:id="_tokenizer_8py_source_1l00017"/>00017 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">return</emphasis>&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a83247dadeaff93d3086e1b1c40d298d4">_statements</link>
<anchor xml:id="_tokenizer_8py_source_1l00018"/>00018 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;
<anchor xml:id="_tokenizer_8py_source_1l00019"/><link linkend="_classtokenizer_1_1_tokenizer_1ad2fb8a15536b87c0cd983e5b9f57f303">00019</link> &#32;&#32;&#32;&#32;<emphasis role="keyword">def&#32;</emphasis><link linkend="_classtokenizer_1_1_tokenizer_1ad2fb8a15536b87c0cd983e5b9f57f303">get_tokens</link>(self,&#32;text)&#32;-&gt;&#32;list:
<anchor xml:id="_tokenizer_8py_source_1l00020"/>00020 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;regex&#32;=&#32;re.compile(self.<link linkend="_classtokenizer_1_1_tokenizer_1a0094707f591524fc876a87c584aea101">_token_pattern</link>)
<anchor xml:id="_tokenizer_8py_source_1l00021"/>00021 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a19ba2b3d3f77a08205b45e8a8512dda6">_tokens</link>=&#32;regex.findall(text)
<anchor xml:id="_tokenizer_8py_source_1l00022"/>00022 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">for</emphasis>&#32;t&#32;<emphasis role="keywordflow">in</emphasis>&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a19ba2b3d3f77a08205b45e8a8512dda6">_tokens</link>:
<anchor xml:id="_tokenizer_8py_source_1l00023"/>00023 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">if</emphasis>&#32;(len(t)==0):&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a19ba2b3d3f77a08205b45e8a8512dda6">_tokens</link>.remove(t)&#32;
<anchor xml:id="_tokenizer_8py_source_1l00024"/>00024 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">return</emphasis>&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a19ba2b3d3f77a08205b45e8a8512dda6">_tokens</link>
<anchor xml:id="_tokenizer_8py_source_1l00025"/>00025 &#32;&#32;&#32;&#32;
<anchor xml:id="_tokenizer_8py_source_1l00026"/><link linkend="_classtokenizer_1_1_tokenizer_1a6a76430445bf5fe58cd4db2def61c330">00026</link> &#32;&#32;&#32;&#32;<emphasis role="keyword">def&#32;</emphasis><link linkend="_classtokenizer_1_1_tokenizer_1a6a76430445bf5fe58cd4db2def61c330">__str__</link>(self)&#32;-&gt;&#32;str:
<anchor xml:id="_tokenizer_8py_source_1l00027"/>00027 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;ret=<emphasis role="stringliteral">&apos;&apos;</emphasis>
<anchor xml:id="_tokenizer_8py_source_1l00028"/>00028 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">for</emphasis>&#32;s&#32;<emphasis role="keywordflow">in</emphasis>&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a83247dadeaff93d3086e1b1c40d298d4">_statements</link>:
<anchor xml:id="_tokenizer_8py_source_1l00029"/>00029 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;ret&#32;+=&#32;f<emphasis role="stringliteral">&quot;statement&#32;-&gt;&#32;{s}&#32;(length&#32;=&#32;{len(s)})\n&quot;</emphasis>
<anchor xml:id="_tokenizer_8py_source_1l00030"/>00030 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">for</emphasis>&#32;t&#32;<emphasis role="keywordflow">in</emphasis>&#32;self.<link linkend="_classtokenizer_1_1_tokenizer_1a19ba2b3d3f77a08205b45e8a8512dda6">_tokens</link>:
<anchor xml:id="_tokenizer_8py_source_1l00031"/>00031 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;ret&#32;+=&#32;f<emphasis role="stringliteral">&quot;token&#32;-&gt;&#32;{t}&#32;(length&#32;=&#32;{len(t)})\n&quot;</emphasis>
<anchor xml:id="_tokenizer_8py_source_1l00032"/>00032 &#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;<emphasis role="keywordflow">return</emphasis>&#32;ret
</programlisting></section>
